{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpkeeyeerpa2024/ADALL_github/blob/main/ADALL_W2S2_7Jan26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load key from Google Colab Secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "# This is the default and can be omitted\n",
        "api_key=api_key,\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "data = 'https://raw.githubusercontent.com/tpkeeyeerpa2024/ADALL_github/refs/heads/main/laptop_prices_2024_sgd_TL.csv'\n",
        "df = pd.read_csv(data)\n",
        "print(\"Data loaded\")\n",
        "\n",
        "# Convert the first few rows to a string to send to OpenAI\n",
        "data_preview = df.head(10).to_csv(index=False)\n",
        "print(data_preview)\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    instructions=\"You are an expert data scientist with extensive knowledge of predictive analysis and linear regression.\",\n",
        "    input=f\"Dataset: Laptop Prices \\nHere are the first 10 rows of the dataset:\\n{data_preview}]\",\n",
        ")\n",
        "print(response.output_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_cIYYkoY4hP",
        "outputId": "6bd001ed-22ba-408f-cb68-c8da00120b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded\n",
            "Brand,Model,CPU,GPU,RAM_GB,Storage_Type,Storage_GB,Touchscreen,Weight_kg,Screen_Size_inch,Discount_percent,Price_SGD,Brand_Discount,Member_Discount\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4070,64,SSD,256,False,1.56,16.0,3.27,2413.36,5,144.8\n",
            "Acer,Nitro 5,AMD Ryzen 9 8900HX,AMD Radeon 780M,32,SSD,1024,True,1.45,14.0,5.03,1773.75,5,124.16\n",
            "Acer,Nitro 5,AMD Ryzen 5 8600H,NVIDIA RTX 4050,32,SSD,2048,False,1.34,14.0,4.41,1634.07,5,98.04\n",
            "Acer,TravelMate P6,Intel Core Ultra 7 15500H,NVIDIA RTX 4060,16,SSD,4096,True,1.18,13.3,2.16,2362.59,5,118.13\n",
            "Acer,Predator Helios 300,Intel i7-14800H,NVIDIA RTX 4070,8,SSD,1024,True,1.31,14.0,6.93,2218.55,5,155.3\n",
            "Acer,Aspire 5,Intel i9-14900HK,NVIDIA RTX 4080,32,SSD,256,False,3.34,17.3,8.94,2224.12,5,155.69\n",
            "Acer,TravelMate P6,Intel i9-14900HK,NVIDIA RTX 4080,128,SSD,1024,True,1.11,13.3,11.72,3016.36,5,211.15\n",
            "Acer,Predator Helios 300,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,True,1.29,13.3,8.84,2579.29,5,180.55\n",
            "Acer,Swift 3,Intel i5-14500H,NVIDIA RTX 4050,64,SSD,4096,False,1.4,13.3,6.92,1976.94,5,98.85\n",
            "Acer,Nitro 5,Intel Core Ultra 9 15700H,NVIDIA RTX 4070,16,SSD,2048,False,1.15,13.3,5.25,2538.34,5,152.3\n",
            "\n",
            "This dataset of laptop prices contains various features that influence the pricing of laptops. To conduct a predictive analysis, particularly using linear regression, we'll need to focus on the following key steps:\n",
            "\n",
            "### 1. Data Cleaning\n",
            "   - **Check for Null Values**: Ensure that there are no missing values in the dataset.\n",
            "   - **Data Types**: Make sure that categorical variables are encoded properly, and numerical features are in the correct format.\n",
            "\n",
            "### 2. Feature Selection\n",
            "We'll need to decide which features to include in our linear regression model. The features present that could have a relationship with `Price_SGD` include:\n",
            "\n",
            "   - **Fuel Features**:\n",
            "     - `CPU`: The processor type (categorical; we may need to one-hot encode this).\n",
            "     - `GPU`: The graphics card (categorical; also needs encoding).\n",
            "     - `RAM_GB`: Amount of RAM (numerical).\n",
            "     - `Storage_Type`: Type of storage (categorical; encoding required).\n",
            "     - `Storage_GB`: Size of storage (numerical).\n",
            "     - `Touchscreen`: Whether it has a touchscreen (boolean; can be converted to binary).\n",
            "     - `Weight_kg`: Weight of the laptop (numerical).\n",
            "     - `Screen_Size_inch`: Size of the screen (numerical).\n",
            "     - `Discount_percent`: Percentage discount (numerical).\n",
            "     - `Brand`: Brand name (categorical; encoding required).\n",
            "\n",
            "### 3. Exploratory Data Analysis (EDA)\n",
            "   - **Visualizations**: Use scatter plots to analyze the relationship between `Price_SGD` and each numerical feature.\n",
            "   - **Correlation Matrix**: Compute correlation coefficients to identify the most influential features.\n",
            "\n",
            "### 4. Model Creation\n",
            "   - **Standardize Numerical Features**: For better model performance.\n",
            "   - **One-Hot Encoding**: Convert categorical brand names, CPU, GPU, etc., into numerical format.\n",
            "   - **Train/Test Split**: Divide the dataset into training and testing sets, typically an 80-20 split.\n",
            "\n",
            "### 5. Model Training\n",
            "   - Use a linear regression model to fit the training data.\n",
            "   - Train the model on the features selected.\n",
            "\n",
            "### 6. Model Evaluation\n",
            "   - **R² Score**: Evaluate how well the model performs.\n",
            "   - **Mean Absolute Error (MAE)**: Measure the average magnitude of the errors in a set of predictions.\n",
            "   - **Residual Analysis**: Plot residuals to check for homoscedasticity.\n",
            "\n",
            "### 7. Predictions\n",
            "   - Use the model to predict prices for unseen data and analyze the results.\n",
            "\n",
            "### 8. Interpretation of Results\n",
            "   - Analyze the coefficients to understand how much each factor contributes to the price.\n",
            "\n",
            "### Example Implementation\n",
            "Here's a pseudocode outline of the steps in Python:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.linear_model import LinearRegression\n",
            "from sklearn.preprocessing import OneHotEncoder\n",
            "from sklearn.metrics import mean_absolute_error, r2_score\n",
            "\n",
            "# Load Dataset\n",
            "data = pd.read_csv('laptop_prices.csv')\n",
            "\n",
            "# Data cleaning (check for nulls, types...)\n",
            "# Encoding categorical features\n",
            "encoder = OneHotEncoder()\n",
            "encoded_features = encoder.fit_transform(data[['CPU', 'GPU', 'Storage_Type', 'Brand']]) \n",
            "\n",
            "# Combine encoded features and drop original categorical columns\n",
            "X = pd.concat([data[['RAM_GB', 'Storage_GB', 'Touchscreen', 'Weight_kg', 'Screen_Size_inch', 'Discount_percent']], \n",
            "                pd.DataFrame(encoded_features.toarray())], axis=1)\n",
            "y = data['Price_SGD']\n",
            "\n",
            "# Train/Test Split\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Model Training\n",
            "model = LinearRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predictions\n",
            "y_pred = model.predict(X_test)\n",
            "\n",
            "# Evaluation\n",
            "print('R² Score:', r2_score(y_test, y_pred))\n",
            "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
            "```\n",
            "\n",
            "### Conclusion\n",
            "By following these steps, you can build a predictive model for laptop prices based on the given dataset, allowing for insights into which features most significantly affect pricing. If you need help with specific code implementations or analyses, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe the dataset size, column types, missing values and highlight any unusual patterns\n",
        "\n",
        "# What does one row of record represents?\n",
        "\n",
        "# What is the target variable?\n",
        "\n",
        "# Is the data clean? Does it contain missing values? How about duplicate values?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KZkAReUbLQS",
        "outputId": "3bc8beb6-5087-4450-ab16-010399c198c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9e0369c"
      },
      "source": [
        "# Task\n",
        "Analyze the structure and quality of the `df` DataFrame by describing its shape, confirming 'Price_SGD' as the target variable, checking data types and non-null counts, identifying duplicate rows, generating descriptive statistics for numerical columns, and analyzing categorical column distributions, then summarize all findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e622a89e"
      },
      "source": [
        "## Describe Dataset Shape and Row Representation\n",
        "\n",
        "### Subtask:\n",
        "Determine the number of rows and columns in the DataFrame (`df.shape`) and clearly state that each row represents a unique laptop model with its specifications and pricing information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afc6df49"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I will print the shape of the DataFrame to show the number of rows and columns, as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0ed582",
        "outputId": "e5a495d2-5a4c-44e8-b7fa-38fba140a026"
      },
      "source": [
        "print(f\"DataFrame shape: {df.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (1000, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "782f8f73"
      },
      "source": [
        "Each row in the DataFrame `df` represents a unique laptop model. It includes various specifications such as Brand, Model, CPU, GPU, RAM, Storage Type and Size, Touchscreen availability, Weight, Screen Size, and pricing details including Discount Percent, Price in SGD, Brand Discount, and Member Discount."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ffb1a12"
      },
      "source": [
        "## Identify Target Variable\n",
        "\n",
        "### Subtask:\n",
        "Confirm that 'Price_SGD' is the target variable for predictive analysis, as identified by the previous analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4cf47e"
      },
      "source": [
        "The target variable for this predictive analysis is `Price_SGD`. This variable represents the price of laptops in Singapore Dollars, which we aim to predict based on other features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066dc662"
      },
      "source": [
        "## Check Data Types and Non-Null Counts\n",
        "\n",
        "### Subtask:\n",
        "Display the DataFrame's information to show column names, their data types, and the count of non-null values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1456cc7"
      },
      "source": [
        "**Reasoning**:\n",
        "To display the DataFrame's information, including column names, their data types, and the count of non-null values, I will use the `.info()` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d51636d8",
        "outputId": "d3b716bd-e080-44b9-8bdc-76d866483679"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 14 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Brand             1000 non-null   object \n",
            " 1   Model             1000 non-null   object \n",
            " 2   CPU               1000 non-null   object \n",
            " 3   GPU               1000 non-null   object \n",
            " 4   RAM_GB            1000 non-null   int64  \n",
            " 5   Storage_Type      1000 non-null   object \n",
            " 6   Storage_GB        1000 non-null   int64  \n",
            " 7   Touchscreen       1000 non-null   bool   \n",
            " 8   Weight_kg         1000 non-null   float64\n",
            " 9   Screen_Size_inch  1000 non-null   float64\n",
            " 10  Discount_percent  1000 non-null   float64\n",
            " 11  Price_SGD         1000 non-null   float64\n",
            " 12  Brand_Discount    1000 non-null   int64  \n",
            " 13  Member_Discount   1000 non-null   float64\n",
            "dtypes: bool(1), float64(5), int64(3), object(5)\n",
            "memory usage: 102.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334543e6"
      },
      "source": [
        "## Check for Duplicate Rows\n",
        "\n",
        "### Subtask:\n",
        "Identify and count any fully duplicated rows in the dataset using `df.duplicated().sum()` to assess data uniqueness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bbdc222"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify and count fully duplicated rows, I will use the `.duplicated()` method combined with `.sum()` on the DataFrame `df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4389314",
        "outputId": "97159165-28b3-44eb-bd10-2d7d9402d00d"
      },
      "source": [
        "duplicate_rows = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicate_rows}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1874c7e7"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask of checking for duplicate rows is complete. Now, I will generate descriptive statistics for the numerical columns in the DataFrame `df` to understand their distribution and central tendencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1910d34",
        "outputId": "2b5bff14-2286-4a41-bfd5-33c59aaa4041"
      },
      "source": [
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            RAM_GB   Storage_GB    Weight_kg  Screen_Size_inch  \\\n",
            "count  1000.000000  1000.000000  1000.000000       1000.000000   \n",
            "mean     53.128000  1505.024000     2.036560         15.645700   \n",
            "std      44.413288  1380.203919     0.746477          1.759846   \n",
            "min       8.000000   256.000000     1.000000         13.300000   \n",
            "25%      16.000000   512.000000     1.340000         14.000000   \n",
            "50%      32.000000  1024.000000     1.970000         15.600000   \n",
            "75%      64.000000  2048.000000     2.680000         17.300000   \n",
            "max     128.000000  4096.000000     3.500000         18.400000   \n",
            "\n",
            "       Discount_percent    Price_SGD  Brand_Discount  Member_Discount  \n",
            "count       1000.000000  1000.000000       1000.0000      1000.000000  \n",
            "mean           7.538230  2277.796410          6.7680       135.810660  \n",
            "std            4.334012   616.496246          2.6346        41.344593  \n",
            "min            0.000000   995.770000          3.0000        50.740000  \n",
            "25%            3.815000  1776.212500          5.0000       103.435000  \n",
            "50%            7.480000  2257.765000          7.0000       131.095000  \n",
            "75%           11.225000  2711.680000         10.0000       163.052500  \n",
            "max           15.000000  4156.500000         10.0000       281.340000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26d04c4a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that descriptive statistics for numerical columns have been generated, I will analyze the distribution of categorical columns. This will involve iterating through each categorical column and using `value_counts()` to display the frequency of each unique category.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6f9506a",
        "outputId": "284dc765-4093-474a-e997-97113a2b7f8f"
      },
      "source": [
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "print(\"\\nDistribution of Categorical Columns:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(df[col].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribution of Categorical Columns:\n",
            "\n",
            "--- Brand ---\n",
            "Brand\n",
            "Asus         177\n",
            "Acer         176\n",
            "Microsoft    174\n",
            "Lenovo       174\n",
            "Dell         163\n",
            "HP           136\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Model ---\n",
            "Model\n",
            "Predator Helios 300      48\n",
            "ExpertBook B9            43\n",
            "Surface Book 3           43\n",
            "Legion 5                 40\n",
            "Alienware M15            38\n",
            "Aspire 5                 38\n",
            "Surface Go 3             38\n",
            "ThinkBook 14s            37\n",
            "XPS 15                   37\n",
            "Surface Pro 8            35\n",
            "TUF Gaming F15           35\n",
            "Swift 3                  35\n",
            "Yoga Slim 7              35\n",
            "ROG Zephyrus G15         34\n",
            "Pavilion 15              34\n",
            "ZenBook 14               33\n",
            "Surface Laptop Studio    33\n",
            "ThinkPad X1 Carbon       32\n",
            "VivoBook S15             32\n",
            "Latitude 7420            32\n",
            "Nitro 5                  31\n",
            "Omen 15                  31\n",
            "IdeaPad 5                30\n",
            "XPS 13                   28\n",
            "Inspiron 15              28\n",
            "Envy 13                  27\n",
            "Surface Laptop 5         25\n",
            "TravelMate P6            24\n",
            "Spectre x360             23\n",
            "EliteBook 840            21\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- CPU ---\n",
            "CPU\n",
            "Intel i5-14600H              114\n",
            "Intel i7-14800H              106\n",
            "Intel i9-14900HK             103\n",
            "Intel i5-14500H              102\n",
            "Intel i7-14700H              101\n",
            "AMD Ryzen 5 8600H            101\n",
            "Intel Core Ultra 7 15500H     99\n",
            "Intel Core Ultra 9 15700H     96\n",
            "AMD Ryzen 9 8900HX            93\n",
            "AMD Ryzen 7 8800H             85\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- GPU ---\n",
            "GPU\n",
            "NVIDIA RTX 4070    268\n",
            "NVIDIA RTX 4080    146\n",
            "NVIDIA RTX 4060    137\n",
            "NVIDIA RTX 4050    114\n",
            "NVIDIA RTX 3050     97\n",
            "Intel Arc A750M     76\n",
            "Intel Iris Xe       71\n",
            "AMD Radeon 780M     56\n",
            "AMD Radeon 680M     35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Storage_Type ---\n",
            "Storage_Type\n",
            "SSD    1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb11915a"
      },
      "source": [
        "### Summary of Dataset Structure and Quality Analysis\n",
        "\n",
        "This analysis has examined the structure and quality of the `df` DataFrame, which contains information on various laptop models.\n",
        "\n",
        "**1. Dataset Shape and Row Representation:**\n",
        "*   The DataFrame `df` has **1000 rows** and **14 columns**, indicating a moderate-sized dataset.\n",
        "*   Each row represents a unique laptop model, detailing its specifications (e.g., Brand, CPU, RAM) and pricing information (e.g., Price_SGD, Discount_percent).\n",
        "\n",
        "**2. Target Variable:**\n",
        "*   The target variable for predictive analysis has been confirmed as `Price_SGD`, representing laptop prices in Singapore Dollars.\n",
        "\n",
        "**3. Data Types and Non-Null Counts:**\n",
        "*   The `df.info()` output shows that all 14 columns have **1000 non-null entries**, indicating **no missing values** across the dataset. This is excellent for data quality.\n",
        "*   Data types are appropriate for their respective columns:\n",
        "    *   `object` for categorical text fields (Brand, Model, CPU, GPU, Storage_Type).\n",
        "    *   `int64` for integer numerical values (RAM_GB, Storage_GB, Brand_Discount).\n",
        "    *   `float64` for continuous numerical values (Weight_kg, Screen_Size_inch, Discount_percent, Price_SGD, Member_Discount).\n",
        "    *   `bool` for boolean values (Touchscreen).\n",
        "\n",
        "**4. Duplicate Rows:**\n",
        "*   There are **0 duplicate rows** in the dataset, confirming the uniqueness of each laptop record.\n",
        "\n",
        "**5. Descriptive Statistics for Numerical Columns:**\n",
        "*   **RAM_GB**: Ranges from 8GB to 128GB, with a mean of ~53GB, showing good variability in RAM options.\n",
        "*   **Storage_GB**: Ranges from 256GB to 4096GB, with a mean of ~1505GB, also indicating diverse storage capacities.\n",
        "*   **Weight_kg**: Ranges from 1.0kg to 3.5kg, with a mean of ~2.04kg.\n",
        "*   **Screen_Size_inch**: Ranges from 13.3 inches to 18.4 inches, with a mean of ~15.65 inches.\n",
        "*   **Discount_percent**: Ranges from 0% to 15%, with a mean of ~7.54%.\n",
        "*   **Price_SGD**: Ranges from ~995 SGD to ~4156 SGD, with a mean of ~2277 SGD, showing a broad price range.\n",
        "*   **Brand_Discount**: Ranges from 3% to 10%, with a mean of ~6.77%.\n",
        "*   **Member_Discount**: Ranges from ~50 SGD to ~281 SGD, with a mean of ~135.81 SGD.\n",
        "\n",
        "**6. Distribution of Categorical Columns:**\n",
        "*   **Brand**: Features 6 brands, with Asus and Acer being the most frequent, and HP being the least frequent.\n",
        "*   **Model**: Contains 30 unique models, with 'Predator Helios 300' (Acer) being the most common, followed by 'ExpertBook B9' (Asus) and 'Surface Book 3' (Microsoft).\n",
        "*   **CPU**: Shows 10 different CPU types, predominantly Intel processors, with 'Intel i5-14600H' being the most frequent.\n",
        "*   **GPU**: Lists 9 distinct GPU types, with 'NVIDIA RTX 4070' being the most common, indicating a strong presence of dedicated graphics cards.\n",
        "*   **Storage_Type**: All laptops use 'SSD', which simplifies this feature as it is not a differentiating factor within this dataset.\n",
        "\n",
        "**Overall Conclusion:**\n",
        "The dataset is clean and well-structured, with no missing values or duplicate rows. All data types are appropriate. The distributions of both numerical and categorical features show good variability, which is beneficial for building a predictive model for `Price_SGD`. The next steps would typically involve feature engineering and model building, given the clean state of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b16819aa"
      },
      "source": [
        "### Summary of Dataset Structure and Quality Analysis\n",
        "\n",
        "This analysis has examined the structure and quality of the `df` DataFrame, which contains information on various laptop models.\n",
        "\n",
        "**1. Dataset Shape and Row Representation:**\n",
        "*   The DataFrame `df` has **1000 rows** and **14 columns**, indicating a moderate-sized dataset.\n",
        "*   Each row represents a unique laptop model, detailing its specifications (e.g., Brand, CPU, RAM) and pricing information (e.g., Price_SGD, Discount_percent).\n",
        "\n",
        "**2. Target Variable:**\n",
        "*   The target variable for predictive analysis has been confirmed as `Price_SGD`, representing laptop prices in Singapore Dollars.\n",
        "\n",
        "**3. Data Types and Non-Null Counts:**\n",
        "*   The `df.info()` output shows that all 14 columns have **1000 non-null entries**, indicating **no missing values** across the dataset. This is excellent for data quality.\n",
        "*   Data types are appropriate for their respective columns:\n",
        "    *   `object` for categorical text fields (Brand, Model, CPU, GPU, Storage_Type).\n",
        "    *   `int64` for integer numerical values (RAM_GB, Storage_GB, Brand_Discount).\n",
        "    *   `float64` for continuous numerical values (Weight_kg, Screen_Size_inch, Discount_percent, Price_SGD, Member_Discount).\n",
        "    *   `bool` for boolean values (Touchscreen).\n",
        "\n",
        "**4. Duplicate Rows:**\n",
        "*   There are **0 duplicate rows** in the dataset, confirming the uniqueness of each laptop record.\n",
        "\n",
        "**5. Descriptive Statistics for Numerical Columns:**\n",
        "*   **RAM_GB**: Ranges from 8GB to 128GB, with a mean of ~53GB, showing good variability in RAM options.\n",
        "*   **Storage_GB**: Ranges from 256GB to 4096GB, with a mean of ~1505GB, also indicating diverse storage capacities.\n",
        "*   **Weight_kg**: Ranges from 1.0kg to 3.5kg, with a mean of ~2.04kg.\n",
        "*   **Screen_Size_inch**: Ranges from 13.3 inches to 18.4 inches, with a mean of ~15.65 inches.\n",
        "*   **Discount_percent**: Ranges from 0% to 15%, with a mean of ~7.54%.\n",
        "*   **Price_SGD**: Ranges from ~995 SGD to ~4156 SGD, with a mean of ~2277 SGD, showing a broad price range.\n",
        "*   **Brand_Discount**: Ranges from 3% to 10%, with a mean of ~6.77%.\n",
        "*   **Member_Discount**: Ranges from ~50 SGD to ~281 SGD, with a mean of ~135.81 SGD.\n",
        "\n",
        "**6. Distribution of Categorical Columns:**\n",
        "*   **Brand**: Features 6 brands, with Asus and Acer being the most frequent, and HP being the least frequent.\n",
        "*   **Model**: Contains 30 unique models, with 'Predator Helios 300' (Acer) being the most common, followed by 'ExpertBook B9' (Asus) and 'Surface Book 3' (Microsoft).\n",
        "*   **CPU**: Shows 10 different CPU types, predominantly Intel processors, with 'Intel i5-14600H' being the most frequent.\n",
        "*   **GPU**: Lists 9 distinct GPU types, with 'NVIDIA RTX 4070' being the most common, indicating a strong presence of dedicated graphics cards.\n",
        "*   **Storage_Type**: All laptops use 'SSD', which simplifies this feature as it is not a differentiating factor within this dataset.\n",
        "\n",
        "**Overall Conclusion:**\n",
        "The dataset is clean and well-structured, with no missing values or duplicate rows. All data types are appropriate. The distributions of both numerical and categorical features show good variability, which is beneficial for building a predictive model for `Price_SGD`. The next steps would typically involve feature engineering and model building, given the clean state of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123cfe76"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize all findings regarding the dataset's size, column types, missing values, duplicates, the target variable, and any observed unusual patterns or characteristics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86b5a006"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset `df` is comprised of 1000 rows and 14 columns, with each row representing a unique laptop model, including specifications and pricing information.\n",
        "*   The target variable for predictive analysis has been confirmed as `Price_SGD`, representing laptop prices in Singapore Dollars.\n",
        "*   The dataset exhibits excellent data quality, with all 14 columns having 1000 non-null entries, indicating a complete absence of missing values.\n",
        "*   Data types are appropriately assigned: 5 `object` columns for categorical text, 3 `int64` columns for integer numerical values, 5 `float64` columns for continuous numerical values, and 1 `bool` column.\n",
        "*   There are 0 duplicate rows in the dataset, confirming the uniqueness of each laptop record.\n",
        "*   Numerical columns show good variability:\n",
        "    *   `RAM_GB` ranges from 8GB to 128GB (mean ~53GB).\n",
        "    *   `Storage_GB` ranges from 256GB to 4096GB (mean ~1505GB).\n",
        "    *   `Weight_kg` ranges from 1.0kg to 3.5kg (mean ~2.04kg).\n",
        "    *   `Screen_Size_inch` ranges from 13.3 to 18.4 inches (mean ~15.65 inches).\n",
        "    *   `Price_SGD` ranges from ~995 SGD to ~4156 SGD (mean ~2277 SGD), indicating a broad price spectrum.\n",
        "*   Categorical columns also exhibit diversity:\n",
        "    *   There are 6 distinct `Brand`s, with Asus and Acer being the most frequent.\n",
        "    *   30 unique `Model`s are present, with 'Predator Helios 300' (Acer) being the most common.\n",
        "    *   10 different `CPU` types are identified, predominantly Intel processors.\n",
        "    *   9 distinct `GPU` types, with 'NVIDIA RTX 4070' being the most common.\n",
        "    *   A notable observation is that `Storage_Type` is uniformly 'SSD' across all entries, making it a non-differentiating feature within this dataset.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Given the dataset's high quality (no missing values or duplicates, appropriate data types), the next logical step would be to proceed with feature engineering to create more predictive variables, such as calculating price per GB of RAM or storage, or categorizing CPU/GPU tiers.\n",
        "*   The uniformity of 'SSD' for `Storage_Type` suggests this column may be dropped or noted as a constant feature if the analysis focuses on differentiating factors; however, it confirms a modern standard for laptop storage in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform data exploration by highlighting the dataset size, column types, missing values and highlight anything unusual. Determine what one row of the daset represents, what the target is, if the data is clean, and if there are any constraints or assumptions.\n"
      ],
      "metadata": {
        "id": "lX8g45MTnXIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d99e226c"
      },
      "source": [
        "# Task\n",
        "Perform a comprehensive exploratory data analysis (EDA) on the `df` DataFrame to understand its structure, quality, and characteristics. This includes describing the dataset's shape and row representation, identifying the target variable ('Price_SGD'), checking data types and non-null counts, identifying duplicate rows, generating descriptive statistics for numerical columns, and analyzing the distribution of categorical columns. Finally, summarize all findings, including any observed unusual patterns or characteristics, and state any identified constraints or assumptions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d40cf800"
      },
      "source": [
        "## Describe Dataset Shape and Row Representation\n",
        "\n",
        "### Subtask:\n",
        "Determine the number of rows and columns in the DataFrame (`df.shape`) and clearly state that each row represents a unique laptop model with its specifications and pricing information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b3ad932"
      },
      "source": [
        "## Identify Target Variable\n",
        "\n",
        "### Subtask:\n",
        "Confirm that 'Price_SGD' is the target variable for predictive analysis, as identified by the previous analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aceaa20"
      },
      "source": [
        "The target variable for this predictive analysis is `Price_SGD`. This variable represents the price of laptops in Singapore Dollars, which we aim to predict based on other features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5793ada1"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize all findings regarding the dataset's size, column types, missing values, duplicates, the target variable, data cleanliness, and any observed unusual patterns or characteristics, including identified constraints or assumptions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c1ac31f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The dataset, `df`, contains 1000 rows and 14 columns.\n",
        "*   Each row in the DataFrame represents a unique laptop model, including its specifications and pricing information.\n",
        "*   The target variable for predictive analysis is confirmed to be `Price_SGD`, which represents laptop prices in Singapore Dollars.\n"
      ]
    }
  ]
}